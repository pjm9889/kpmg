{"cells":[{"cell_type":"markdown","metadata":{"id":"7RugCy2KwlFv"},"source":["# 3. 데이터 불러오기\n","\n","딥러닝을 포함한 머신러닝의 근원은 데이터다. 따라서 데이터의 수집, 가공, 사용 방법에 따라 모델 성능이 크게 달라질 수 있으며 데이터의 형태는 매우 다양하기 때문에 데이터를 잘 불러오는 것은 가장 중요한 단계 중 하나다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uhxYHQotwlF-"},"outputs":[],"source":["import torch # 파이토치 기본 라이브러리\n","import torchvision # 이미지 관련 된 파이토치 라이브러리\n","import torchvision.transforms as tr # 이미지 전처리 기능들을 제공하는 라이브러리\n","from torch.utils.data import DataLoader, Dataset # 데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리\n","import numpy as np # 넘파이 기본 라이브러리"]},{"cell_type":"markdown","metadata":{"id":"yfZJ6yVFwlF_"},"source":["## 3.1 파이토치 제공 데이터 사용"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ikDNDryOwlF_"},"outputs":[],"source":["# tr.Compose 내에 원하는 전처리를 차례대로 넣어주면 된다.\n","\n","transf = tr.Compose([tr.Resize(16),tr.ToTensor()]) # 16x16으로 이미지 크기 변환 후 텐서 타입으로 변환한다. tr.Resize((16,16))\n","\n","# Transforms on PIL Image\n","# Pad, Grayscale, RandomCrop, Normalize ..\n","# Transforms on torch.*Tensor - tensor image\n","# torchvision.transforms.ToPILImage(mode=None)...\n","# ...\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1943,"status":"ok","timestamp":1676363903640,"user":{"displayName":"딥러닝호형","userId":"11263585794403583722"},"user_tz":-60},"id":"TKsBJMOLwlGA","outputId":"2da4378e-d102-4e74-9279-a1079b2cfd45"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["# torchvision.datasets에서 제공하는 CIFAR10 데이터를 불러온다.\n","# root에는 다운로드 받을 경로를 입력한다.\n","# train=Ture이면 학습 데이터를 불러오고 train=False이면 테스트 데이터를 불러온다.\n","# 미리 선언한 전처리를 사용하기 위해 transform=transf을 작성한다.\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transf)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1676363903878,"user":{"displayName":"딥러닝호형","userId":"11263585794403583722"},"user_tz":-60},"id":"_DgnpPXnwlGB","outputId":"cbc90e74-be46-4a25-9e86-f044df20a7c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 16, 16])\n"]}],"source":["# 일반적으로 데이터셋은 이미지와 라벨이 동시에 들어있는 튜플(tuple) 형태다. (이미지, 라벨)\n","# trainset[0]은 학습 데이터의 첫 번째 데이터로 이미지 한 장과 라벨 숫자 하나가 저장되어 있다.\n","# 즉, trainset[0][0]은 이미지이며 trainset[0][1]은 라벨이다.\n","\n","print(trainset[0][0].size())\n","\n","# 현재 이미지 사이즈는 3x16x16이다. 여기서 3은 채널 수를 말하고 16x16은 이미지의 너비와 높이를 의미한다.\n","# 일반적인 컬러 사진은 RGB 이미지이기 때문에 채널이 3개 이고 (높이)x(너비)x(채널 수)로 크기가 표현된다.\n","# 하지만 파이토치에서는 이미지 한 장이 (채널 수)x(높이)x(너비)으로 표현되니 유의하도록 한다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B10b8fwDwlGC"},"outputs":[],"source":["# DataLoader는 데이터를 미니 배치 형태로 만들어 준다.\n","# 따라서 배치 사이즈 및 셔플 여부 등을 선택할 수 있다.\n","trainloader = DataLoader(trainset, batch_size=50, shuffle=True)\n","testloader = DataLoader(testset, batch_size=50, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":227,"status":"ok","timestamp":1676363917225,"user":{"displayName":"딥러닝호형","userId":"11263585794403583722"},"user_tz":-60},"id":"N1c9NVqKwlGC","outputId":"167d84d7-be5a-4157-9916-21eb7c164bac"},"outputs":[{"data":{"text/plain":["1000"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["len(trainloader)\n","# CIFAR10의 학습 이미지는 50,000장이고 배치 사이즈가 50장이므로 1,000은 배치의 개수가 된다.\n","# 즉 trainloader가 잘 만들어졌다는 것을 단편적으로 알 수 있다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":313,"status":"ok","timestamp":1676363921107,"user":{"displayName":"딥러닝호형","userId":"11263585794403583722"},"user_tz":-60},"id":"f7OvIBgfwlGD","outputId":"bda88171-762d-49d3-a0e8-6e2447c34cbb"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([50, 3, 16, 16])\n"]}],"source":["# iter, next를 이용해 일부 데이터를 확인할 수 있다.\n","dataiter = iter(trainloader)\n","images, labels = next(dataiter)\n","\n","print(images.size())\n","# 일반적으로 학습 데이터는 4차원 형태로 모델에서 사용된다.\n","# (배치 크기)x(채널 수)x(높이)x(너비)"]},{"cell_type":"markdown","metadata":{"id":"4HNsa177wlGD"},"source":["## 3.2 같은 클래스 별로 폴더를 정리한 경우"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cabCxEb_wlGE"},"outputs":[],"source":["# 데이터가 같은 클래스 별로 미리 폴더를 정리 된 경우, ImageFolder의 1줄 선언으로 개인 데이터를 사용할 수 있다.\n","# 별도의 라벨링이 필요 없으며 폴더 별로 자동으로 라벨링을 한다.\n","# 예를 들어 class 폴더에 tiger, lion 폴더(./class/tiger와 ./class/lion)를 미리 만든다.\n","# 다음으로 ImageFolder에 상위 폴더 ./class를 입력하면 이미지와 라벨이 정리 되어 데이터를 불러온다.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1684,"status":"ok","timestamp":1676363956244,"user":{"displayName":"딥러닝호형","userId":"11263585794403583722"},"user_tz":-60},"id":"LGoDEHxNnQQ2","outputId":"3bca9b34-6421-4b1f-cd3c-cc6d26ea1026"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 3, 128, 128]) tensor([0, 1])\n"]}],"source":["dataiter = iter(trainloader)\n","images, labels = next(dataiter)\n","\n","print(images.size(), labels)"]},{"cell_type":"markdown","metadata":{"id":"OEf1xivnwlGE"},"source":["## 3.3 정형화 되지 않은 커스텀 데이터 불러오기(3.2를 사용할 수 없는 경우)\n","\n","\n","1) 라벨 별로 아름답게 폴더 정리가 되어 있으면 매우 좋겠지만 그렇지 않은 경우가 매우 많다.\n","\n","2) 다른 작업들과 공유 된 데이터인 경우 폴더를 함부로 정리할 수 없다.\n","\n","3) 이미지 데이터라도 이미지가 아닌 텍스트, 리스트, 배열 등으로 저장 되어 있는 경우도 있다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1679673021476,"user":{"displayName":"딥러닝호형","userId":"11263585794403583722"},"user_tz":-60},"id":"2_soZ7DBwlGE","outputId":"ec5e96f7-ca32-43d6-badc-40b460f7791c"},"outputs":[{"name":"stdout","output_type":"stream","text":["(100, 32, 32, 3) (100, 1)\n"]}],"source":["# 32x32 컬러 이미지와 라벨이 각각 100장이 있다고 가정하다.\n","\n","train_images = np.random.randint(256,size=(100,32,32,3)) # (이미지 수)x(높이)x(너비)x(채널 수)\n","train_labels = np.random.randint(2,size=(100,1)) # 라벨 수\n","\n","# 이미지 전처리 작업이 필요할 경우 openCV와 같은 라이브러리를 이용하여 이 곳에서 작업할 수도 있다.\n","......\n","#......\n","#......\n","#train_images, train_labels = preprocessing(train_images, train_labels)\n","#......\n","#......\n","#......\n","\n","print(train_images.shape, train_labels.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pt6PIROIwlGF"},"outputs":[],"source":["\"\"\"\n","from torch.utils.data import Dataset\n","\n","class MyDataset(Dataset):\n","\n","    def __init__(self):\n","\n","    def __getitem__(self, index):\n","\n","    def __len__(self):\n","\n","\n","\"\"\"\n","\n","class TensorData(Dataset):\n","\n","    def __init__(self, x_data, y_data):\n","        self.x_data = torch.FloatTensor(x_data) # 이미지 데이터를 FloatTensor로 변형\n","        self.x_data = self.x_data.permute(0,3,1,2) # (이미지 수)x(높이)x(너비)x(채널 수) -> (배치 크기)x(채널 수)x(높이)x(너비)\n","        self.y_data = torch.LongTensor(y_data) # 라벨 데이터를 LongTensor로 변형\n","        self.len = self.y_data.shape[0]\n","\n","    def __getitem__(self, index):\n","        return self.x_data[index], self.y_data[index] # 뽑아 낼 데이터를 적어준다.\n","\n","    def __len__(self):\n","        return self.len\n","\n","# 파이토치에서는 (배치 크기)x(채널 수)x(너비)x(높이) 데이터가 사용 되므로 원래 데이터 (이미지 수)x(높이)x(너비)x(채널 수)를 변경해야만 한다.\n","# permute에서 0(이미지 수), 1(높이), 2(너비), 3(채널 수)을 0(이미지 수), 3(채널 수), 1(높이),2 (너비)로 바꿔주는 것이기 때문에\n","# .permute(0,3,1,2)을 사용하는 것이다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wc4NWa17wlGF"},"outputs":[],"source":["train_data = TensorData(train_images,train_labels) # 텐서 데이터 불러오기\n","train_loader = DataLoader(train_data, batch_size=10, shuffle=True) # 미니 배치 형태로 데이터 갖추기"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1679673049950,"user":{"displayName":"딥러닝호형","userId":"11263585794403583722"},"user_tz":-60},"id":"MtdblxUY1r5c","outputId":"7d841736-6ee0-4150-8b15-fa57030dcf69"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([10, 3, 32, 32]) torch.Size([10, 1])\n"]}],"source":["dataiter = iter(train_loader)\n","images, labels = next(dataiter)\n","\n","print(images.size(), labels.size())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gR4tToZvFU7V"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":0}
{"cells":[{"cell_type":"markdown","metadata":{"id":"mv-7ZDSy7eyB"},"source":["# 3. 데이터 불러오기(심화편)\n","\n","딥러닝을 포함한 머신러닝의 근원은 데이터다. 따라서 데이터의 수집, 가공, 사용 방법에 따라 모델 성능이 크게 달라질 수 있으며 데이터의 형태는 매우 다양하기 때문에 데이터를 잘 불러오는 것은 가장 중요한 단계 중 하나다."]},{"cell_type":"markdown","metadata":{"id":"D0UgOCTE7eyL"},"source":["## 3.4 커스텀 데이터 + 커스텀 전처리\n","\n","이 번에는 텐서 생성 부분에서 이미지 전처리를 진행한다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D36c4wrK7eyM"},"outputs":[],"source":["import torch\n","import torchvision.transforms as tr # 이미지 전처리 기능들을 제공하는 라이브러리\n","from torch.utils.data import DataLoader, Dataset # 데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리\n","import numpy as np # 넘파이 기본 라이브러리"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v9nVhHCO7eyN"},"outputs":[],"source":["# 32x32 컬러 이미지와 라벨이 각각 100장이 있다고 가정하다.\n","# glob -> PIL, openCV ..\n","train_images = np.random.randint(256,size=(100,32,c 2,3)) # (이미지 수)x(높이)x(너비)x(채널 수)\n","train_labels = np.random.randint(2,size=(100,1)) # 라벨 수\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uzd0tSIy7eyN"},"outputs":[],"source":["# 3.3에서 사용한 양식을 그대로 사용하되 전처리 작업을 할 수 있도록 transform을 추가한다.\n","class MyDataset(Dataset):\n","\n","    def __init__(self, x_data, y_data, transform=None):\n","\n","        self.x_data = x_data # 넘파이 배열이 들어온다.\n","        self.y_data = y_data # 넘파이 배열이 들어온다.\n","        self.transform = transform\n","        self.len = len(y_data)\n","\n","    def __getitem__(self, index):\n","        sample = self.x_data[index], self.y_data[index]\n","\n","        if self.transform:\n","            sample = self.transform(sample) #self.transform이 None이 아니라면 전처리를 작업한다.\n","\n","        return sample # 3.3과 다르게 넘파이 배열로 출력 되는 것에 유의 하도록 한다.\n","\n","    def __len__(self):\n","        return self.len"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j6XlSNsi7eyO"},"outputs":[],"source":["# 전처리 기술을 직접 만들어 보자.\n","# 이 때 위 기본 양식과 같이 사용하기 위해 call 함수를 사용한다.\n","# def __call__ 내의 원하는 전처리 작업을 프로그래밍 할 수 있다.\n","\n","# 1. 텐서 변환\n","class ToTensor:\n","    def __call__(self, sample):\n","        inputs, labels = sample\n","        inputs = torch.FloatTensor(inputs) # 텐서로 변환\n","        inputs = inputs.permute(2,0,1) # 크기 변환\n","        return inputs, torch.LongTensor(labels) # 텐서로 변환\n","\n","# 2. 선형식\n","class LinearTensor:\n","\n","    def __init__(self, slope=1, bias=0):\n","        self.slope = slope\n","        self.bias = bias\n","\n","    def __call__(self, sample):\n","        inputs, labels = sample\n","        inputs = self.slope*inputs + self.bias # ax+b 계산하기\n","        return inputs, labels\n","\n","# .....\n","# 추가로 계속 원하는 전처리를 정의하자.\n","# ....."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KqlNPurj7eyO"},"outputs":[],"source":["trans = tr.Compose([ToTensor(),LinearTensor(2,5)]) # 텐서 변환 후 선형식 2x+5 연산\n","dataset1 = MyDataset(train_images,train_labels, transform=trans)\n","train_loader1 = DataLoader(dataset1, batch_size=10, shuffle=True)\n","\n","# ToTensor()와 tr.ToTensor()의 차이\n","# 앞 서 사용한 tr.ToTensor()는 import torchvision.transforms as tr를 이용한 파이토치 메소드를 이용한 것이고\n","# ToTensor()는 위에서 정의 된 메소드를 사용한 것이다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":235,"status":"ok","timestamp":1679673875437,"user":{"displayName":"딥러닝호형","userId":"11263585794403583722"},"user_tz":-60},"id":"9rQ1xcTK7eyO","outputId":"d911b97b-bfca-4c25-9b34-b00a01baf3d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([10, 3, 32, 32])\n"]}],"source":["dataiter1 = iter(train_loader1)\n","images1, labels1 = next(dataiter1) # 버전 업데이트 후 .next는 동작하지 않음\n","print(images1.size()) # 배치 및 이미지 크기 확인"]},{"cell_type":"markdown","metadata":{"id":"Z5N_eyyQ7eyQ"},"source":["## 3.5 커스텀 데이터 + torchvision.transforms 전처리"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLRWLT8F7eyQ"},"outputs":[],"source":["# torchvision.transforms에서 제공하는 전처리 기술을 사용한다.\n","# torchvision.transforms은 입력 이미지가 일반적으로 PILImage 타입이나 텐서일 경우에 동작한다.\n","# 현재 데이터는 넘파이 배열이다. 따라서 텐서 변환 후 tr.ToPILImage()을 이용하여 PILImage 타입으로 만들어 준다.\n","# __call__을 이용한 기본 구조는 동일하다.\n","\n","class MyTransform:\n","\n","    def __call__(self, sample):\n","        inputs, labels = sample\n","        inputs = torch.FloatTensor(inputs)\n","        inputs = inputs.permute(2,0,1)\n","        labels = torch.LongTensor(labels)\n","\n","        transf = tr.Compose([tr.ToPILImage(), tr.Resize(128),tr.ToTensor(),tr.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","        final_output = transf(inputs)\n","\n","        return final_output, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"saoSFgDT7eyR"},"outputs":[],"source":["dataset2 = MyDataset(train_images,train_labels, transform=MyTransform())\n","train_loader2 = DataLoader(dataset2, batch_size=15, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1679674065778,"user":{"displayName":"딥러닝호형","userId":"11263585794403583722"},"user_tz":-60},"id":"6cKZ6llQ7eyR","outputId":"10760b0d-4444-4f8b-d04b-4e5c20dbe5ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([15, 3, 128, 128])\n"]}],"source":["dataiter2 = iter(train_loader2)\n","images2, labels2 = next(dataiter2)\n","print(images2.size()) # 배치 및 이미지 크기 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LumAqRvt-Hes"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":0}